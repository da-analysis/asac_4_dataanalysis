# Databricks notebook source
# MAGIC %md
# MAGIC ## ê°ì„± ë¶„ì„ (ëª¨ë“  ë°ì´í„° í•©ì³ì„œ)

# COMMAND ----------

from pyspark.sql import SparkSession
import pyspark.pandas as ps
import matplotlib.pyplot as plt

# í…Œì´ë¸” ì½ê¸°
cell_meta = spark.read.table("asac.meta_cell_phones_and_accessories_new_price2")
sport_meta = spark.read.table("asac.sports_and_outdoors_fin_v2")
cell_review = spark.read.table("asac.review_cellphone_accessories_final")
sport_review = spark.read.table("asac.reivew_sports_outdoor_final")


# pyspark pandas DataFrameìœ¼ë¡œ ë³€ê²½
cell_meta = ps.DataFrame(cell_meta)
sport_meta = ps.DataFrame(sport_meta)
cell_review = ps.DataFrame(cell_review)
sport_review = ps.DataFrame(sport_review)

# COMMAND ----------

display(cell_review)

# COMMAND ----------

# reviewText, asin, reviewerID ë§Œ ë½‘ì•„ì„œ í…Œì´ë¸” í•©ì¹˜ê¸°
from pyspark.sql import SparkSession
spark = SparkSession.builder.getOrCreate()

cell_review_text = spark.read.table("asac.review_cellphone_accessories_final").select("reviewText","asin","reviewerID","overall","reviewTime")
sport_review_text = spark.read.table("asac.reivew_sports_outdoor_final").select("reviewText","asin","reviewerID","overall","reviewTime")

review_text = cell_review_text.union(sport_review_text)

review_text.show(truncate=False)

# COMMAND ----------

# MAGIC %md
# MAGIC ### 1. vivekn ëª¨ë¸ ê°ì„± ë¶„ì„
# MAGIC - https://sparknlp.org/2021/11/22/sentiment_vivekn_en.html

# COMMAND ----------

import sparknlp
from sparknlp.base import *
from sparknlp.annotator import *
from pyspark.ml import Pipeline

from pyspark.sql import SparkSession
from pyspark.sql.functions import explode

# COMMAND ----------

review_text.createOrReplaceTempView("review_text")

# COMMAND ----------

display(review_text)

# COMMAND ----------

document = DocumentAssembler() \
.setInputCol("reviewText") \
.setOutputCol("document")

token = Tokenizer() \
.setInputCols(["document"]) \
.setOutputCol("token")

normalizer = Normalizer() \
.setInputCols(["token"]) \
.setOutputCol("normal")

vivekn =  ViveknSentimentModel.pretrained() \
.setInputCols(["document", "normal"]) \
.setOutputCol("result_sentiment")

finisher = Finisher() \
.setInputCols(["result_sentiment"]) \
.setOutputCols("final_sentiment")

pipeline = Pipeline().setStages([document, token, normalizer, vivekn, finisher])

# COMMAND ----------

pipelineModel = pipeline.fit(review_text)
result = pipelineModel.transform(review_text)

# COMMAND ----------

display(result)

# COMMAND ----------

result = result.withColumn("final_sentiment", explode('final_sentiment'))
display(result)

# COMMAND ----------



# COMMAND ----------



# COMMAND ----------



# COMMAND ----------



# COMMAND ----------

# MAGIC %md
# MAGIC ### 2. í—ˆê¹…í˜ì´ìŠ¤ transformer í™œìš©
# MAGIC - ìŠ¤íƒ€, ì ìˆ˜ ì¶”ì¶œí•´ì„œ í”¼ì³ë¡œ ë§Œë“¤ê¸°
# MAGIC - 1 starëŠ” ë§¤ìš° ë¶€ì •ì , 3starsëŠ” ì¤‘ë¦½, 5starsëŠ” ë§¤ìš° ê¸ì •ì 
# MAGIC - scoreëŠ” í•´ë‹¹ê°ì •ì— ì†í•  í™•ë¥ 
# MAGIC
# MAGIC - ì‘ì—…ì´ ì˜¤ë˜ê±¸ë¦¬ë©´ mulitprocessing ë¼ì´ë¸ŒëŸ¬ë¦¬ ì°¸ê³ í•´ì„œ ì½”ë“œ ìˆ˜ì •í•´ì„œ ëŒë ¤ë³´ê¸° (or joblib)
# MAGIC - ì…ë ¥ë°ì´í„° ì¡°ê±´ì´ ìˆìŒ... 512....ì´ê±° ì˜ë¼ì„œ í• ì§€??
# MAGIC - showëŠ” ë˜ëŠ”ë°, display ì•ˆë˜ëŠ” ê²½ìš°

# COMMAND ----------

!pip install --upgrade pip

# COMMAND ----------

!pip install huggingface_hub

# COMMAND ----------

!pip install langchain_community
from langchain_community.embeddings import HuggingFaceHubEmbeddings

# COMMAND ----------

!pip install torch torchvision torchaudio

# COMMAND ----------

# MAGIC %pip install torch torchvision

# COMMAND ----------

# MAGIC %pip install transformers
# MAGIC %pip install langchain_community
# MAGIC from langchain_community.embeddings import HuggingFaceHubEmbeddings

# COMMAND ----------

from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline
import torch

# ê°ì • ë¶„ì„ì„ ìœ„í•œ ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸ ë¡œë“œ
model_name = "nlptown/bert-base-multilingual-uncased-sentiment"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSequenceClassification.from_pretrained(model_name)

# íŒŒì´í”„ë¼ì¸ ì„¤ì • (ê°ì • ë¶„ì„)
sentiment_analysis_pipeline = pipeline("sentiment-analysis", model=model, tokenizer=tokenizer)

# ë¬¸ì„œ ì˜ˆì‹œ
documents = [
    "I love Hugging Face!", 
    "I hate Hugging Face...",
    "Hugging Face is just okay."
]

# ë¬¸ì„œ ê°ì • ë¶„ì„
for doc in documents:
    result = sentiment_analysis_pipeline(doc)
    print(f"Document: {doc}")
    print(f"Sentiment: {result[0]['label']}, Score: {result[0]['score']}")
    print()


# COMMAND ----------

from pyspark.sql import SparkSession
from pyspark.sql.functions import udf
from pyspark.sql.types import StringType, ArrayType, StructType, StructField, FloatType

# SparkSession ìƒì„±
spark = SparkSession.builder \
    .appName("Sentiment Analysis") \
    .getOrCreate()


# PyTorch ë° Transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ import
from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline
import torch

# ê°ì • ë¶„ì„ì„ ìœ„í•œ ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸ ë¡œë“œ
model_name = "nlptown/bert-base-multilingual-uncased-sentiment"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSequenceClassification.from_pretrained(model_name)

# íŒŒì´í”„ë¼ì¸ ì„¤ì • (ê°ì • ë¶„ì„)
sentiment_analysis_pipeline = pipeline("sentiment-analysis", model=model, tokenizer=tokenizer)

# UDF ì •ì˜
def analyze_sentiment(text):
    result = sentiment_analysis_pipeline(text)
    label = result[0]['label']
    score = result[0]['score']
    return f"Sentiment: {label}, Score: {score}"

# UDF ë“±ë¡
analyze_sentiment_udf = udf(analyze_sentiment, StringType())

# review_text_dfì— UDF ì ìš©
result_df = review_text.limit(10).withColumn("sentiment_analysis", analyze_sentiment_udf("reviewText"))

# ê²°ê³¼ ì¶œë ¥
result_df.show(truncate=False)


# COMMAND ----------

display(result_df)

# COMMAND ----------

# UDF ì •ì˜
def analyze_sentiment(text):
    #text = text[:512]  #  maximum 512 tokens
    result = sentiment_analysis_pipeline(text)
    label = result[0]['label']
    score = result[0]['score']
    return label, score

# UDF ë“±ë¡ ë° ìŠ¤í‚¤ë§ˆ ì •ì˜
analyze_sentiment_udf = udf(analyze_sentiment, StructType([
    StructField("Sentiment", StringType(), True),
    StructField("Score", FloatType(), True)
]))

# review_text_dfì— UDF ì ìš©
result_df = review_text.limit(100).withColumn("sentiment_analysis", analyze_sentiment_udf("reviewText"))


# COMMAND ----------

display(result_df)

# COMMAND ----------

from pyspark.sql import SparkSession
from pyspark.sql.functions import udf
from pyspark.sql.types import StringType, ArrayType, StructType, StructField, FloatType

# SparkSession ìƒì„±
spark = SparkSession.builder \
    .appName("Sentiment Analysis") \
    .getOrCreate()


# PyTorch ë° Transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ import
from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline
import torch

# ê°ì • ë¶„ì„ì„ ìœ„í•œ ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸ ë¡œë“œ
model_name = "nlptown/bert-base-multilingual-uncased-sentiment"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSequenceClassification.from_pretrained(model_name)

# íŒŒì´í”„ë¼ì¸ ì„¤ì • (ê°ì • ë¶„ì„)
sentiment_analysis_pipeline = pipeline("sentiment-analysis", model=model, tokenizer=tokenizer)

# UDF ì •ì˜
def analyze_sentiment(text):
    text = text[:512]
    result = sentiment_analysis_pipeline(text)
    label = result[0]['label']
    score = result[0]['score']
    return f"Sentiment: {label}, Score: {score}"

# UDF ë“±ë¡
analyze_sentiment_udf = udf(analyze_sentiment, StringType())

# review_text_dfì— UDF ì ìš©
result_df = review_text.limit(1000).withColumn("sentiment_analysis", analyze_sentiment_udf("reviewText"))

# ê²°ê³¼ ì¶œë ¥
result_df.show(truncate=False)


# COMMAND ----------

display(result_df)

# COMMAND ----------

from pyspark.sql.types import IntegerType, FloatType
from pyspark.sql.functions import udf

def extract_star(label):
    try:
        star = int(label.split()[0])
        return star
    except ValueError:
        return None


# UDF ë“±ë¡
extract_star_udf = udf(extract_star, IntegerType())

result_df = result_df.withColumn("star", extract_star_udf("sentiment_analysis"))

result_df = result_df.withColumn("score", result_df["sentiment_analysis"].substr(-7, 7).cast(FloatType()))

# ê²°ê³¼ ì¶œë ¥
result_df.show(truncate=False)

# COMMAND ----------

display(result_df)

# COMMAND ----------



# COMMAND ----------



# COMMAND ----------



# COMMAND ----------

# MAGIC %md
# MAGIC ### 3. ê¸ë¶€ì •ìœ¼ë¡œ ë‚˜ì˜¤ëŠ” ê²ƒ
# MAGIC - ì—¬ê¸°ì„œ scoreëŠ” í•´ë‹¹ ê°ì •ì— ì†í•  í™•ë¥ ì„ ë‚˜íƒ€ëƒ„

# COMMAND ----------

!pip install transformers

# COMMAND ----------

from transformers import pipeline

# COMMAND ----------

!pip install torch torchvision torchaudio

# COMMAND ----------

# MAGIC %pip install torch torchvision

# COMMAND ----------

from transformers import pipeline

# build pipeline
classifier = pipeline("sentiment-analysis")

#inference
classifier("we are very happy to show you the ğŸ¤— Transformers library.")

# COMMAND ----------

from pyspark.sql.functions import udf
from pyspark.sql.types import StringType, FloatType, StructType, StructField

classifier = pipeline("sentiment-analysis")

def analyze_sentiment(text):
    text = text[:512]  #  maximum 512 tokens
    result = classifier(text)[0]
    label = result['label']
    score = result['score']
    return label, score

analyze_sentiment_udf = udf(analyze_sentiment, StructType([
    StructField("label", StringType(), True),
    StructField("score", FloatType(), True)
]))

result_df = review_text.withColumn("sentiment_analysis", analyze_sentiment_udf("reviewText"))

result_df = result_df.withColumn("label", result_df["sentiment_analysis"].getField("label")) \
                     .withColumn("score", result_df["sentiment_analysis"].getField("score")) \
                     .drop("sentiment_analysis")

result_df.show(truncate=False)


# COMMAND ----------

display(result_df.head(100))

# COMMAND ----------


